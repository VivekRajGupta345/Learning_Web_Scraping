{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-08 14:03:41 [scrapy.utils.log] INFO: Scrapy 1.7.3 started (bot: scrapybot)\n",
      "2019-10-08 14:03:41 [scrapy.utils.log] INFO: Versions: lxml 4.3.3.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.7.0, Python 3.6.8 |Anaconda, Inc.| (default, Feb 21 2019, 18:30:04) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.18362-SP0\n",
      "2019-10-08 14:03:41 [scrapy.crawler] INFO: Overridden settings: {}\n",
      "2019-10-08 14:03:41 [scrapy.extensions.telnet] INFO: Telnet Password: e896aaeea729186e\n",
      "2019-10-08 14:03:41 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2019-10-08 14:03:42 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2019-10-08 14:03:42 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2019-10-08 14:03:42 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2019-10-08 14:03:42 [scrapy.core.engine] INFO: Spider opened\n",
      "2019-10-08 14:03:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2019-10-08 14:03:42 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2019-10-08 14:03:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/> (referer: None)\n",
      "2019-10-08 14:03:42 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/>\n",
      "{'titletext': ['Quotes to Scrape']}\n",
      "2019-10-08 14:03:42 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2019-10-08 14:03:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 218,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 2333,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 0.486231,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2019, 10, 8, 8, 33, 42, 760054),\n",
      " 'item_scraped_count': 1,\n",
      " 'log_count/DEBUG': 2,\n",
      " 'log_count/INFO': 10,\n",
      " 'response_received_count': 1,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2019, 10, 8, 8, 33, 42, 273823)}\n",
      "2019-10-08 14:03:42 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quotes to Scrape\n"
     ]
    }
   ],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "class QuoteSpider(scrapy.Spider):\n",
    "    name= \"quotes_title\"\n",
    "    start_urls=[\"http://quotes.toscrape.com/\"\n",
    "               ]\n",
    "    \n",
    "    def parse(self,response):\n",
    "        title=response.css(\"title::text\").extract()\n",
    "        yield {\"titletext\":title}\n",
    "        print (title[0])\n",
    "        \n",
    "process=CrawlerProcess()\n",
    "process.crawl(QuoteSpider)\n",
    "process.start() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-08 14:35:59 [scrapy.utils.log] INFO: Scrapy 1.7.3 started (bot: scrapybot)\n",
      "2019-10-08 14:35:59 [scrapy.utils.log] INFO: Versions: lxml 4.3.3.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.7.0, Python 3.6.8 |Anaconda, Inc.| (default, Feb 21 2019, 18:30:04) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.18362-SP0\n",
      "2019-10-08 14:35:59 [scrapy.crawler] INFO: Overridden settings: {}\n",
      "2019-10-08 14:35:59 [scrapy.extensions.telnet] INFO: Telnet Password: c12436bf989a5942\n",
      "2019-10-08 14:35:59 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2019-10-08 14:35:59 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2019-10-08 14:35:59 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2019-10-08 14:35:59 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2019-10-08 14:35:59 [scrapy.core.engine] INFO: Spider opened\n",
      "2019-10-08 14:35:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2019-10-08 14:35:59 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2019-10-08 14:36:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/> (referer: None)\n",
      "2019-10-08 14:36:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/>\n",
      "{'first_quote': ['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\", '“Try not to become a man of success. Rather become a man of value.”', '“It is better to be hated for what you are than to be loved for what you are not.”', \"“I have not failed. I've just found 10,000 ways that won't work.”\", \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\", '“A day without sunshine is like, you know, night.”']}\n",
      "2019-10-08 14:36:00 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2019-10-08 14:36:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 218,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 2333,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 0.491916,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2019, 10, 8, 9, 6, 0, 371928),\n",
      " 'item_scraped_count': 1,\n",
      " 'log_count/DEBUG': 2,\n",
      " 'log_count/INFO': 10,\n",
      " 'response_received_count': 1,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2019, 10, 8, 9, 5, 59, 880012)}\n",
      "2019-10-08 14:36:00 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\n"
     ]
    }
   ],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "class firstquote(scrapy.Spider):\n",
    "    name=\"first_quote\"\n",
    "    start_urls=['http://quotes.toscrape.com/']\n",
    "    \n",
    "    def parse(self,response):  \n",
    "        global first_quote1\n",
    "        first_quote1=response.css(\"span.text::text\").extract()\n",
    "        yield{\"first_quote\":first_quote1}\n",
    "        print(first_quote1[2])\n",
    "        \n",
    "        \n",
    "process=CrawlerProcess()\n",
    "process.crawl(firstquote)\n",
    "process.start() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”',\n",
       " '“It is our choices, Harry, that show what we truly are, far more than our abilities.”',\n",
       " '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”',\n",
       " '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”',\n",
       " \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\",\n",
       " '“Try not to become a man of success. Rather become a man of value.”',\n",
       " '“It is better to be hated for what you are than to be loved for what you are not.”',\n",
       " \"“I have not failed. I've just found 10,000 ways that won't work.”\",\n",
       " \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\",\n",
       " '“A day without sunshine is like, you know, night.”']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_quote1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-08 16:32:04 [scrapy.utils.log] INFO: Scrapy 1.7.3 started (bot: scrapybot)\n",
      "2019-10-08 16:32:04 [scrapy.utils.log] INFO: Versions: lxml 4.3.3.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.7.0, Python 3.6.8 |Anaconda, Inc.| (default, Feb 21 2019, 18:30:04) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.18362-SP0\n",
      "2019-10-08 16:32:04 [scrapy.crawler] INFO: Overridden settings: {}\n",
      "2019-10-08 16:32:04 [scrapy.extensions.telnet] INFO: Telnet Password: f94d05c23a285134\n",
      "2019-10-08 16:32:04 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2019-10-08 16:32:04 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2019-10-08 16:32:04 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2019-10-08 16:32:05 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2019-10-08 16:32:05 [scrapy.core.engine] INFO: Spider opened\n",
      "2019-10-08 16:32:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2019-10-08 16:32:05 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2019-10-08 16:32:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/> (referer: None)\n",
      "2019-10-08 16:32:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/>\n",
      "{'first_quote': ['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\", '“Try not to become a man of success. Rather become a man of value.”', '“It is better to be hated for what you are than to be loved for what you are not.”', \"“I have not failed. I've just found 10,000 ways that won't work.”\", \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\", '“A day without sunshine is like, you know, night.”']}\n",
      "2019-10-08 16:32:05 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2019-10-08 16:32:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 218,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 2333,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 0.627384,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2019, 10, 8, 11, 2, 5, 634906),\n",
      " 'item_scraped_count': 1,\n",
      " 'log_count/DEBUG': 2,\n",
      " 'log_count/INFO': 10,\n",
      " 'response_received_count': 1,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2019, 10, 8, 11, 2, 5, 7522)}\n",
      "2019-10-08 16:32:05 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”', '“It is our choices, Harry, that show what we truly are, far more than our abilities.”', '“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”', '“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”', \"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\", '“Try not to become a man of success. Rather become a man of value.”', '“It is better to be hated for what you are than to be loved for what you are not.”', \"“I have not failed. I've just found 10,000 ways that won't work.”\", \"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\", '“A day without sunshine is like, you know, night.”']\n"
     ]
    }
   ],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "class firstquote(scrapy.Spider):\n",
    "    name=\"first_quote\"\n",
    "    start_urls=['http://quotes.toscrape.com/']\n",
    "    \n",
    "    def parse(self,response):  \n",
    "        global first_quote1\n",
    "        first_quote1=response.css(\".text::text\").extract()#In this cell I used the selector provided by the selector gadget\n",
    "        yield{\"first_quote\":first_quote1}\n",
    "        \n",
    "        \n",
    "process=CrawlerProcess()\n",
    "process.crawl(firstquote)\n",
    "process.start() \n",
    "print(first_quote1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above cell the path has been located by using a tool selectorGadget instead of viewing the page source code manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-08 19:16:58 [scrapy.utils.log] INFO: Scrapy 1.7.3 started (bot: scrapybot)\n",
      "2019-10-08 19:16:58 [scrapy.utils.log] INFO: Versions: lxml 4.3.3.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.7.0, Python 3.6.8 |Anaconda, Inc.| (default, Feb 21 2019, 18:30:04) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.18362-SP0\n",
      "2019-10-08 19:16:58 [scrapy.crawler] INFO: Overridden settings: {}\n",
      "2019-10-08 19:16:59 [scrapy.extensions.telnet] INFO: Telnet Password: 5e6f512ce2addd44\n",
      "2019-10-08 19:16:59 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2019-10-08 19:16:59 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2019-10-08 19:16:59 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2019-10-08 19:16:59 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2019-10-08 19:16:59 [scrapy.core.engine] INFO: Spider opened\n",
      "2019-10-08 19:16:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2019-10-08 19:16:59 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2019-10-08 19:16:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/> (referer: None)\n",
      "2019-10-08 19:16:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/>\n",
      "{'tags': ['<a href=\"/page/2/\">Next <span aria-hidden=\"true\">→</span></a>']}\n",
      "2019-10-08 19:16:59 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2019-10-08 19:16:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 218,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 2333,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 0.50929,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2019, 10, 8, 13, 46, 59, 826953),\n",
      " 'item_scraped_count': 1,\n",
      " 'log_count/DEBUG': 2,\n",
      " 'log_count/INFO': 10,\n",
      " 'response_received_count': 1,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2019, 10, 8, 13, 46, 59, 317663)}\n",
      "2019-10-08 19:16:59 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<a href=\"/page/2/\">Next <span aria-hidden=\"true\">→</span></a>']\n"
     ]
    }
   ],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "base_url=\"http://quotes.toscrape.com/\"\n",
    "class link_quote(scrapy.Spider):\n",
    "    name=\"tags\"\n",
    "    start_urls=[\"http://quotes.toscrape.com/\"]    \n",
    "    \n",
    "    def parse(self,response):\n",
    "        global link_tag\n",
    "        link_tag=response.css(\".next a\").extract() ### Not using text as in above cells as in this cas we need the a href tag and if we use ::text then it will return next.\n",
    "        yield{\"tags\":link_tag}\n",
    "        \n",
    "process=CrawlerProcess()\n",
    "process.crawl(link_quote)\n",
    "process.start()\n",
    "print(link_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/page/2/\n",
      "http://quotes.toscrape.com//page/2/\n"
     ]
    }
   ],
   "source": [
    "new_url=\"\"\n",
    "for i in range(0,len(link_tag[0])):\n",
    "    if link_tag[0][i]=='\"':\n",
    "        j=i+1\n",
    "        while(link_tag[0][j]!='\"'):\n",
    "            new_url=new_url+link_tag[0][j]\n",
    "            j=j+1\n",
    "        break\n",
    "print(new_url)\n",
    "new_url=base_url+new_url\n",
    "print(new_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above two cells we found how to find the link to next web page.\n",
    "We can use this new url to be fed into start_urls to continue our scraping to multiple pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-08 23:15:00 [scrapy.utils.log] INFO: Scrapy 1.7.3 started (bot: scrapybot)\n",
      "2019-10-08 23:15:00 [scrapy.utils.log] INFO: Versions: lxml 4.3.3.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.7.0, Python 3.6.8 |Anaconda, Inc.| (default, Feb 21 2019, 18:30:04) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.18362-SP0\n",
      "2019-10-08 23:15:01 [scrapy.crawler] INFO: Overridden settings: {}\n",
      "2019-10-08 23:15:01 [scrapy.extensions.telnet] INFO: Telnet Password: c7f46efaf899eb68\n",
      "2019-10-08 23:15:01 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2019-10-08 23:15:01 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2019-10-08 23:15:01 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2019-10-08 23:15:01 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2019-10-08 23:15:01 [scrapy.core.engine] INFO: Spider opened\n",
      "2019-10-08 23:15:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2019-10-08 23:15:01 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2019-10-08 23:15:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/> (referer: None)\n",
      "2019-10-08 23:15:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/>\n",
      "{'tags': [<Selector xpath=\"descendant-or-self::*[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ') and (count(preceding-sibling::*) = 0)]/descendant-or-self::*/*[@class and contains(concat(' ', normalize-space(@class), ' '), ' tags ')]\" data='<div class=\"tags\">\\n            Tags:\\n...'>]}\n",
      "2019-10-08 23:15:01 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2019-10-08 23:15:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 218,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 2333,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 0.490503,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2019, 10, 8, 17, 45, 1, 860926),\n",
      " 'item_scraped_count': 1,\n",
      " 'log_count/DEBUG': 2,\n",
      " 'log_count/INFO': 10,\n",
      " 'response_received_count': 1,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2019, 10, 8, 17, 45, 1, 370423)}\n",
      "2019-10-08 23:15:01 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['change', 'deep-thoughts', 'thinking', 'world']\n"
     ]
    }
   ],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "base_url=\"http://quotes.toscrape.com/\"\n",
    "class link_quote(scrapy.Spider):\n",
    "    name=\"tags\"\n",
    "    start_urls=[\"http://quotes.toscrape.com/\"]\n",
    "    \n",
    "    def parse(self,response):\n",
    "        global gy\n",
    "        link_tag=response.css(\".quote:nth-child(1) .tags\")\n",
    "        gy=link_tag.css(\"a::text\").extract()\n",
    "        yield{\"tags\":link_tag}\n",
    "        \n",
    "process=CrawlerProcess()\n",
    "process.crawl(link_quote)\n",
    "process.start()\n",
    "print(gy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-09 10:30:04 [scrapy.utils.log] INFO: Scrapy 1.7.3 started (bot: scrapybot)\n",
      "2019-10-09 10:30:04 [scrapy.utils.log] INFO: Versions: lxml 4.3.3.0, libxml2 2.9.9, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.7.0, Python 3.6.8 |Anaconda, Inc.| (default, Feb 21 2019, 18:30:04) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1c  28 May 2019), cryptography 2.7, Platform Windows-10-10.0.18362-SP0\n",
      "2019-10-09 10:30:04 [scrapy.crawler] INFO: Overridden settings: {}\n",
      "2019-10-09 10:30:04 [scrapy.extensions.telnet] INFO: Telnet Password: 2b76ba40c495ccfc\n",
      "2019-10-09 10:30:04 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2019-10-09 10:30:05 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2019-10-09 10:30:05 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2019-10-09 10:30:05 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2019-10-09 10:30:05 [scrapy.core.engine] INFO: Spider opened\n",
      "2019-10-09 10:30:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2019-10-09 10:30:05 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2019-10-09 10:30:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/> (referer: None)\n",
      "2019-10-09 10:30:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/>\n",
      "{'tags': [<Selector xpath=\"descendant-or-self::*[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ') and (count(preceding-sibling::*) = 0)]/descendant-or-self::*/*[@class and contains(concat(' ', normalize-space(@class), ' '), ' tags ')]\" data='<div class=\"tags\">\\n            Tags:\\n...'>]}\n",
      "2019-10-09 10:30:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://quotes.toscrape.com/>\n",
      "{'tags': [<Selector xpath=\"descendant-or-self::*[@class and contains(concat(' ', normalize-space(@class), ' '), ' quote ') and (count(preceding-sibling::*) = 1)]/descendant-or-self::*/*[@class and contains(concat(' ', normalize-space(@class), ' '), ' tags ')]\" data='<div class=\"tags\">\\n            Tags:\\n...'>]}\n",
      "2019-10-09 10:30:05 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2019-10-09 10:30:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 218,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 2333,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 0.482559,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2019, 10, 9, 5, 0, 5, 718509),\n",
      " 'item_scraped_count': 2,\n",
      " 'log_count/DEBUG': 3,\n",
      " 'log_count/INFO': 10,\n",
      " 'response_received_count': 1,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2019, 10, 9, 5, 0, 5, 235950)}\n",
      "2019-10-09 10:30:05 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['change', 'deep-thoughts', 'thinking', 'world'], ['abilities', 'choices']]\n"
     ]
    }
   ],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "base_url=\"http://quotes.toscrape.com/\"\n",
    "class link_quote(scrapy.Spider):\n",
    "    name=\"tags\"\n",
    "    start_urls=[\"http://quotes.toscrape.com/\"]\n",
    "    \n",
    "    def parse(self,response):\n",
    "        global gy,arr\n",
    "        arr=[]\n",
    "        for i in range(1,3):\n",
    "            link_tag=response.css(\".quote:nth-child(\"+str(i)+\") .tags\")\n",
    "            gy=link_tag.css(\"a::text\").extract()\n",
    "            arr.append(gy)\n",
    "            yield{\"tags\":link_tag}\n",
    "        \n",
    "process=CrawlerProcess()\n",
    "process.crawl(link_quote)\n",
    "process.start()\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This way i can scrape the tags such that they do not mix and can be later used to make a dataset with proper indexing with other attributes.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 278,
   "position": {
    "height": "40px",
    "left": "1023px",
    "right": "20px",
    "top": "57px",
    "width": "277px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
